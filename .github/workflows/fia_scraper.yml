name: FIA Scraper

on:
  schedule:
    # ‚è±Ô∏è Every 5 minutes on Friday (5), Saturday (6), Sunday (0) ‚Äì Race weekends
    - cron: '*/5 * * * 5'
    - cron: '*/5 * * * 6'
    - cron: '*/5 * * * 0'
    # üïê Daily check at 01:00 UTC (early enough to catch pre-9AM events)
    - cron: '0 1 * * 1'
    - cron: '0 1 * * 2'
    - cron: '0 1 * * 3'
    - cron: '0 1 * * 4'
  workflow_dispatch:
    inputs:
      force:
        description: "Force run regardless of race weekend"
        required: false
        default: "false"
  push:
    paths:
      - "fia_scraper/**"
      - ".github/workflows/fia_scraper.yml"

jobs:
  scrape-and-notify:
    runs-on: ubuntu-24.04

    env:
      DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
      DISCORD_ERROR_WEBHOOK_URL: ${{ secrets.DISCORD_ERROR_WEBHOOK_URL }}

    steps:
      # ‚úÖ Step 1: Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4

      # üêç Step 2: Setup Python
      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: 3.12

      # üì¶ Step 3: Install Python dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # üîÅ Step 4: Restore document hash cache (with fallback)
      - name: Restore cache of processed documents
        id: cache-restore
        uses: actions/cache@v4
        with:
          path: last_fia_doc_hash.txt
          key: fia-doc-cache-v2-${{ github.run_id }}
          restore-keys: |
            fia-doc-cache-v2-

      # üß† Step 5: Run the scraper
      - name: Run FIA scraper
        run: |
          xvfb-run --auto-servernum python fia_scraper/scraper.py ${{ inputs.force == 'true' && '--force' || '' }}

      # üíæ Step 6: Save updated document hash cache
      - name: Save updated cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: last_fia_doc_hash.txt
          key: fia-doc-cache-v2-${{ github.run_id }}
